



Fundamental lemma of the calculus of variations - Wikipedia


























Jump to content







Main menu





Main menu
move to sidebar
hide



		Navigation
	


Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate





		Contribute
	


HelpLearn to editCommunity portalRecent changesUpload file



















Search











Search





























Create account

Log in








Personal tools





 Create account Log in





		Pages for logged out editors learn more



ContributionsTalk




























Contents
move to sidebar
hide




(Top)





1
Basic version








2
Proof








3
Version for two given functions








4
Versions for discontinuous functions








5
Higher derivatives








6
Vector-valued functions








7
Multivariable functions








8
Applications








9
Notes








10
References


















Toggle the table of contents







Fundamental lemma of the calculus of variations



8 languages




DeutschFrançais한국어ItalianoעבריתPortuguêsРусский中文

Edit links











ArticleTalk





English

















ReadEditView history







Tools





Tools
move to sidebar
hide



		Actions
	


ReadEditView history





		General
	


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item





		Print/export
	


Download as PDFPrintable version

























From Wikipedia, the free encyclopedia


Initial result in using test functions to find extremum
In mathematics, specifically in the calculus of variations, a variation δf of a function f can be concentrated on an arbitrarily small interval, but not a single point.
Accordingly, the necessary condition of extremum (functional derivative equal zero) appears in a weak formulation (variational form) integrated with an arbitrary function δf. The fundamental lemma of the calculus of variations is typically used to transform this weak formulation into the strong formulation (differential equation), free of the integration with arbitrary function. The proof usually exploits the possibility to choose δf concentrated on an interval on which f keeps sign (positive or negative). Several versions of the lemma are in use. Basic versions are easy to formulate and prove. More powerful versions are used when needed.


Basic version[edit]
If a continuous function 



f


{\displaystyle f}

 on an open interval 



(
a
,
b
)


{\displaystyle (a,b)}

 satisfies the equality





∫

a


b


f
(
x
)
h
(
x
)


d

x
=
0


{\displaystyle \int _{a}^{b}f(x)h(x)\,\mathrm {d} x=0}


for all compactly supported smooth functions 



h


{\displaystyle h}

 on 



(
a
,
b
)


{\displaystyle (a,b)}

, then 



f


{\displaystyle f}

 is identically zero.[1][2]
Here "smooth" may be interpreted as "infinitely differentiable",[1] but often is interpreted as "twice continuously differentiable" or "continuously differentiable" or even just "continuous",[2] since these weaker statements may be strong enough for a given task. "Compactly supported" means "vanishes outside 



[
c
,
d
]


{\displaystyle [c,d]}

 for some 



c


{\displaystyle c}

, 



d


{\displaystyle d}

 such that 



a
<
c
<
d
<
b


{\displaystyle a<c<d<b}

";[1] but often a weaker statement suffices, assuming only that 



h


{\displaystyle h}

 (or 



h


{\displaystyle h}

 and a number of its derivatives) vanishes at the endpoints 



a


{\displaystyle a}

, 



b


{\displaystyle b}

;[2] in this case the closed interval 



[
a
,
b
]


{\displaystyle [a,b]}

 is used.

Proof[edit]
Suppose 



f
(



x
¯



)
≠
0


{\displaystyle f({\bar {x}})\neq 0}

 for some 






x
¯



∈
(
a
,
b
)


{\displaystyle {\bar {x}}\in (a,b)}

. Since 



f


{\displaystyle f}

 is continuous, it is nonzero with the same sign for some 



c
,
d


{\displaystyle c,d}

 such that 



a
<
c
<



x
¯



<
d
<
b


{\displaystyle a<c<{\bar {x}}<d<b}

. Without loss of generality, assume 



f
(



x
¯



)
>
0


{\displaystyle f({\bar {x}})>0}

. Then take an 



h


{\displaystyle h}

 that is positive on 



c
,
d


{\displaystyle c,d}

 and zero elsewhere, for example 





h
(
x
)
=


{



exp
⁡

(

−


1

(
x
−
c
)
(
d
−
x
)




)

,


c
<
x
<
d




0
,



o
t
h
e
r
w
i
s
e









{\displaystyle h(x)={\begin{cases}\exp \left(-{\frac {1}{(x-c)(d-x)}}\right),&c<x<d\\0,&\mathrm {otherwise} \end{cases}}}

.
Note this bump function satisfies the properties in the statement, including 




C

∞




{\displaystyle C^{\infty }}

. Since






∫

a


b


f
(
x
)
h
(
x
)
d
x
>
0
,


{\displaystyle \int _{a}^{b}f(x)h(x)dx>0,}


we reach a contradiction.[3]

Version for two given functions[edit]
If a pair of continuous functions f, g on an interval (a,b) satisfies the equality





∫

a


b


(
f
(
x
)

h
(
x
)
+
g
(
x
)


h
′

(
x
)
)


d

x
=
0


{\displaystyle \int _{a}^{b}(f(x)\,h(x)+g(x)\,h'(x))\,\mathrm {d} x=0}


for all compactly supported smooth functions h on (a,b), then g is differentiable, and g' = f  everywhere.[4][5]
The special case for g = 0 is just the basic version.
Here is the special case for f = 0 (often sufficient).

If a continuous function g on an interval (a,b) satisfies the equality





∫

a


b


g
(
x
)


h
′

(
x
)


d

x
=
0


{\displaystyle \int _{a}^{b}g(x)\,h'(x)\,\mathrm {d} x=0}


for all smooth functions h on (a,b) such that 



h
(
a
)
=
h
(
b
)
=
0


{\displaystyle h(a)=h(b)=0}

, then g is constant.[6]
If, in addition, continuous differentiability of g is assumed, then integration by parts reduces both statements to the basic version; this case is attributed to Joseph-Louis Lagrange, while the proof of differentiability of g is due to Paul du Bois-Reymond.

Versions for discontinuous functions[edit]
The given functions (f, g) may be discontinuous, provided that they are locally integrable (on the given interval). In this case, Lebesgue integration is meant, the conclusions hold almost everywhere (thus, in all continuity points), and differentiability of g is interpreted as local absolute continuity (rather than continuous differentiability).[7][8] Sometimes the given functions are assumed to be piecewise continuous, in which case Riemann integration suffices, and the conclusions are stated everywhere except the finite set of discontinuity points.[5]

Higher derivatives[edit]
If a tuple of continuous functions 




f

0


,

f

1


,
…
,

f

n




{\displaystyle f_{0},f_{1},\dots ,f_{n}}

 on an interval (a,b) satisfies the equality





∫

a


b


(

f

0


(
x
)

h
(
x
)
+

f

1


(
x
)


h
′

(
x
)
+
⋯
+

f

n


(
x
)


h

(
n
)


(
x
)
)


d

x
=
0


{\displaystyle \int _{a}^{b}(f_{0}(x)\,h(x)+f_{1}(x)\,h'(x)+\dots +f_{n}(x)\,h^{(n)}(x))\,\mathrm {d} x=0}


for all compactly supported smooth functions h on (a,b), then there exist continuously differentiable functions 




u

0


,

u

1


,
…
,

u

n
−
1




{\displaystyle u_{0},u_{1},\dots ,u_{n-1}}

 on (a,b) such that









f

0





=

u

0

′

,





f

1





=

u

0


+

u

1

′

,





f

2





=

u

1


+

u

2

′





⋮





f

n
−
1





=

u

n
−
2


+

u

n
−
1

′

,





f

n





=

u

n
−
1








{\displaystyle {\begin{aligned}f_{0}&=u'_{0},\\f_{1}&=u_{0}+u'_{1},\\f_{2}&=u_{1}+u'_{2}\\\vdots \\f_{n-1}&=u_{n-2}+u'_{n-1},\\f_{n}&=u_{n-1}\end{aligned}}}


everywhere.[9]
This necessary condition is also sufficient, since the integrand becomes 



(

u

0


h

)
′

+
(

u

1



h
′


)
′

+
⋯
+
(

u

n
−
1



h

(
n
−
1
)



)
′

.


{\displaystyle (u_{0}h)'+(u_{1}h')'+\dots +(u_{n-1}h^{(n-1)})'.}


The case n = 1 is just the version for two given functions, since 



f
=

f

0


=

u

0

′



{\displaystyle f=f_{0}=u'_{0}}

 and 




f

1


=

u

0


,


{\displaystyle f_{1}=u_{0},}

 thus, 




f

0


−

f

1

′

=
0.


{\displaystyle f_{0}-f'_{1}=0.}


In contrast, the case n=2 does not lead to the relation 




f

0


−

f

1

′

+

f

2

″

=
0
,


{\displaystyle f_{0}-f'_{1}+f''_{2}=0,}

 since the function 




f

2


=

u

1




{\displaystyle f_{2}=u_{1}}

 need not be differentiable twice. The sufficient condition 




f

0


−

f

1

′

+

f

2

″

=
0


{\displaystyle f_{0}-f'_{1}+f''_{2}=0}

 is not necessary. Rather, the necessary and sufficient condition may be written as 




f

0


−
(

f

1


−

f

2

′


)
′

=
0


{\displaystyle f_{0}-(f_{1}-f'_{2})'=0}

 for n=2, 




f

0


−
(

f

1


−
(

f

2


−

f

3

′


)
′


)
′

=
0


{\displaystyle f_{0}-(f_{1}-(f_{2}-f'_{3})')'=0}

 for n=3, and so on; in general, the brackets cannot be opened because of non-differentiability.

Vector-valued functions[edit]
Generalization to vector-valued functions 



(
a
,
b
)
→


R


d




{\displaystyle (a,b)\to \mathbb {R} ^{d}}

 is straightforward; one applies the results for scalar functions to each coordinate separately,[10] or treats the vector-valued case from the beginning.[11]

Multivariable functions[edit]
If a continuous multivariable function f on an open set 



Ω
⊂


R


d




{\displaystyle \Omega \subset \mathbb {R} ^{d}}

 satisfies the equality





∫

Ω


f
(
x
)

h
(
x
)


d

x
=
0


{\displaystyle \int _{\Omega }f(x)\,h(x)\,\mathrm {d} x=0}


for all compactly supported smooth functions h on Ω, then f is identically zero.
Similarly to the basic version, one may consider a continuous function f on the closure of Ω, assuming that h vanishes on the boundary of Ω (rather than compactly supported).[12]
Here is a version for discontinuous multivariable functions.

Let 



Ω
⊂


R


d




{\displaystyle \Omega \subset \mathbb {R} ^{d}}

 be an open set, and 



f
∈

L

2


(
Ω
)


{\displaystyle f\in L^{2}(\Omega )}

 satisfy the equality





∫

Ω


f
(
x
)

h
(
x
)


d

x
=
0


{\displaystyle \int _{\Omega }f(x)\,h(x)\,\mathrm {d} x=0}


for all compactly supported smooth functions h on Ω. Then f=0 (in L2, that is, almost everywhere).[13]
Applications[edit]
This lemma is used to prove that extrema of the functional





J
[
y
]
=

∫


x

0





x

1




L
(
t
,
y
(
t
)
,



y
˙



(
t
)
)


d

t


{\displaystyle J[y]=\int _{x_{0}}^{x_{1}}L(t,y(t),{\dot {y}}(t))\,\mathrm {d} t}


are  weak solutions 



y
:
[

x

0


,

x

1


]
→
V


{\displaystyle y:[x_{0},x_{1}]\to V}

 (for an appropriate vector space 



V


{\displaystyle V}

) of the Euler–Lagrange equation








∂
L
(
t
,
y
(
t
)
,



y
˙



(
t
)
)


∂
y



=



d



d

t






∂
L
(
t
,
y
(
t
)
,



y
˙



(
t
)
)


∂



y
˙






.


{\displaystyle {\partial L(t,y(t),{\dot {y}}(t)) \over \partial y}={\mathrm {d}  \over \mathrm {d} t}{\partial L(t,y(t),{\dot {y}}(t)) \over \partial {\dot {y}}}.}


The Euler–Lagrange equation plays a prominent role in classical mechanics and differential geometry.

Notes[edit]

^ a b c Jost & Li-Jost 1998, Lemma 1.1.1 on p.6

^ a b c Gelfand & Fomin 1963, Lemma 1 on p.9 (and Remark)

^ Liberzon 2012, Lemma 2.1 on p.37

^ Gelfand & Fomin 1963, Lemma 4 on p.11

^ a b Hestenes 1966, Lemma 15.1 on p.50

^ Gelfand & Fomin 1963, Lemma 2 on p.10

^ Jost & Li-Jost 1998, Lemma 1.2.1 on p.13

^ Giaquinta & Hildebrandt 1996, section 2.3: Mollifiers

^ Hestenes 1966, Lemma 13.1 on p.105

^ Gelfand & Fomin 1963, p.35

^ Jost & Li-Jost 1998

^ Gelfand & Fomin 1963, Lemma on p.22; the proof applies in both situations.

^ Jost & Li-Jost 1998, Lemma 3.2.3 on p.170


References[edit]
Jost, Jürgen; Li-Jost, Xianqing (1998), Calculus of variations, Cambridge University
Gelfand, I.M.; Fomin, S.V. (1963), Calculus of variations, Prentice-Hall (transl. from Russian).
Hestenes, Magnus R. (1966), Calculus of variations and optimal control theory, John Wiley
Giaquinta, Mariano; Hildebrandt, Stefan (1996), Calculus of Variations I, Springer
Liberzon, Daniel (2012), Calculus of Variations and Optimal Control Theory, Princeton University Press




Retrieved from "https://en.wikipedia.org/w/index.php?title=Fundamental_lemma_of_the_calculus_of_variations&oldid=1224225297"
Categories: Classical mechanicsCalculus of variationsSmooth functionsLemmas in analysisHidden categories: Articles with short descriptionShort description is different from Wikidata






 This page was last edited on 17 May 2024, at 00:59 (UTC).
Text is available under the Creative Commons Attribution-ShareAlike License 4.0;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Code of Conduct
Developers
Statistics
Cookie statement
Mobile view













Toggle limited content width







